# Tokenizer

O Tokenizer da OpenAI é uma ferramenta para tokenizar textos. Ele é capaz de dividir um texto em sentenças e palavras, além de identificar a posição de cada palavra no texto original.

## Documentação e Acesso ao Serviço

Clique [aqui](https://platform.openai.com/tokenizer) para ver a documentação e acessar o serviço.